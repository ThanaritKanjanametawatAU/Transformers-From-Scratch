{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu128\n",
      "True\n",
      "NVIDIA GeForce RTX 5090\n",
      "(12, 0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_capability(0))\n",
    "torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence of 5 Tokens\n",
    "seq_len = 5\n",
    "d_model = 512\n",
    "positional_encoding = torch.zeros(seq_len, d_model)\n",
    "positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_index = torch.arange(0, 512, 2)\n",
    "odd_index = torch.arange(1, 512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = torch.arange(seq_len, dtype=torch.float).unsqueeze(1)\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding[:, even_index] += torch.sin(position / (10000 ** (even_index/d_model)))\n",
    "positional_encoding[:, odd_index] += torch.cos(position / (10000 ** (even_index/d_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0.1411,     -0.9900,      0.2451,     -0.9695,      0.3428,\n",
       "            -0.9394,      0.4336,     -0.9011,      0.5173,     -0.8558,\n",
       "             0.5936,     -0.8048,      0.6624,     -0.7491,      0.7239,\n",
       "            -0.6899,      0.7783,     -0.6279,      0.8257,     -0.5641,\n",
       "             0.8665,     -0.4992,      0.9010,     -0.4338,      0.9296,\n",
       "            -0.3685,      0.9528,     -0.3036,      0.9708,     -0.2397,\n",
       "             0.9842,     -0.1771,      0.9933,     -0.1160,      0.9984,\n",
       "            -0.0566,      1.0000,      0.0009,      0.9984,      0.0563,\n",
       "             0.9940,      0.1097,      0.9870,      0.1608,      0.9778,\n",
       "             0.2098,      0.9666,      0.2565,      0.9536,      0.3010,\n",
       "             0.9392,      0.3433,      0.9236,      0.3835,      0.9068,\n",
       "             0.4215,      0.8892,      0.4576,      0.8708,      0.4917,\n",
       "             0.8518,      0.5238,      0.8324,      0.5542,      0.8126,\n",
       "             0.5828,      0.7927,      0.6097,      0.7725,      0.6350,\n",
       "             0.7523,      0.6588,      0.7322,      0.6811,      0.7121,\n",
       "             0.7021,      0.6922,      0.7217,      0.6724,      0.7402,\n",
       "             0.6529,      0.7574,      0.6337,      0.7736,      0.6147,\n",
       "             0.7888,      0.5961,      0.8029,      0.5778,      0.8162,\n",
       "             0.5599,      0.8285,      0.5424,      0.8401,      0.5253,\n",
       "             0.8509,      0.5085,      0.8610,      0.4922,      0.8705])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_encoding[3, :100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is actually not used. It's converted to Log term in the code, solving too many zeros problem. Derivation Down Below\n",
    "<div align=\"center\">\n",
    "<img src=\"/media/ssd1/UdemyCourses/Transformers-From-Scratch/assets/PE_LogTerm.png\" width=\"800\" alt=\"Positional Encoding Log Term\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "seq_len = 5\n",
    "\n",
    "# Create a matrix of shape (seq_len, d_model)\n",
    "positional_encoding = torch.zeros(seq_len, d_model)\n",
    "\n",
    "# Temp tensor to help Replicate the formula in the paper\n",
    "position = torch.arange(seq_len, dtype=torch.float).unsqueeze(1)\n",
    "even_index = torch.arange(0, d_model, 2)\n",
    "odd_index = torch.arange(1, d_model, 2)\n",
    "div_term = torch.exp(even_index * -math.log(10000)/d_model)\n",
    "\n",
    "# Formula from the paper section 3.5\n",
    "positional_encoding[:, even_index] += torch.sin(position * div_term)\n",
    "positional_encoding[:, odd_index] += torch.cos(position * div_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0.0000,      1.0000,      0.0000,  ...,      1.0000,\n",
       "              0.0000,      1.0000],\n",
       "        [     0.8415,      0.5403,      0.8219,  ...,      1.0000,\n",
       "              0.0001,      1.0000],\n",
       "        [     0.9093,     -0.4161,      0.9364,  ...,      1.0000,\n",
       "              0.0002,      1.0000],\n",
       "        [     0.1411,     -0.9900,      0.2451,  ...,      1.0000,\n",
       "              0.0003,      1.0000],\n",
       "        [    -0.7568,     -0.6536,     -0.6572,  ...,      1.0000,\n",
       "              0.0004,      1.0000]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(math.sin(1/2 * math.pi), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
